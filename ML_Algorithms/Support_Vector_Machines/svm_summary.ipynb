{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "1. [Quick Start](#Quick_Start)\n",
    "   1. [Load Libraries and Data](#loads)\n",
    "   2. [Instantiating Models and Define Hyperparameters](#Hyperparameters)\n",
    "   3. [Training and Classifying](#Train_Classify)\n",
    "   \n",
    "2. [Pros and Cons](#pros_cons)\n",
    "\n",
    "3. [References and Further Reading](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Quick Start <a class=\"anchor\" id=\"Quick_Start\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.A - Load Libraries and Data <a class=\"anchor\" id=\"loads\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature and target data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.B - Instantiating Models and Define Hyperparameters <a id=\"Hyperparameters\"></a>\n",
    "\n",
    "\"*C is a parameter of the SVC learner and is the penalty for misclassifying a data point. When C is small, the classifier is okay with misclassified data points (high bias but low variance). When C is large, the classifier is heavily penalized for misclassified data and therefore bends over backwards avoid any misclassified data points (low bias but high variance).*\" - Chris Albun in [Support Vector Classifier](https://chrisalbon.com/machine_learning/support_vector_machines/support_vector_classifier/) card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameter C\n",
    "C = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before choice the Kernel Function, please read [1.4.6. Kernel functions](https://scikit-learn.org/stable/modules/svm.html#kernel-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Kernel function \n",
    "kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create support vector classifier\n",
    "svc = SVC(kernel='linear', C=4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.C - Training and Classifying <a id=\"Train_Classify\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = svc.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new observation\n",
    "new_observation = [[-0.7, 1.1, -1.1 , -1.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict class of new observation\n",
    "svc.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  0.55861082, -1.16971425, -0.92054774],\n",
       "       [-1.62768839, -1.74335684, -1.39706395, -1.18381211],\n",
       "       [ 0.79566902, -0.59237301,  0.47857113,  0.3957741 ],\n",
       "       [-1.14301691, -1.51316008, -0.26031542, -0.26238682],\n",
       "       [-0.29484182, -0.13197948,  0.42173371,  0.3957741 ],\n",
       "       [ 0.4321654 , -1.97355361,  0.42173371,  0.3957741 ],\n",
       "       [ 0.06866179,  0.32841405,  0.59224599,  0.79067065],\n",
       "       [ 0.55333328, -1.28296331,  0.64908342,  0.3957741 ],\n",
       "       [ 1.03800476, -0.13197948,  0.70592084,  0.65903847],\n",
       "       [ 0.18982966, -0.82256978,  0.76275827,  0.52740629],\n",
       "       [-0.53717756, -0.13197948,  0.42173371,  0.3957741 ],\n",
       "       [-0.90068117, -1.28296331, -0.4308277 , -0.13075464],\n",
       "       [-1.14301691, -1.28296331,  0.42173371,  0.65903847],\n",
       "       [ 0.18982966, -1.97355361,  0.70592084,  0.3957741 ],\n",
       "       [ 0.4321654 , -0.59237301,  0.59224599,  0.79067065],\n",
       "       [ 0.31099753, -0.13197948,  0.64908342,  0.79067065],\n",
       "       [ 1.64384411, -0.13197948,  1.16062026,  0.52740629],\n",
       "       [ 0.55333328, -0.59237301,  0.76275827,  0.3957741 ],\n",
       "       [ 0.18982966, -0.13197948,  0.59224599,  0.79067065]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the found support vectors \n",
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Pros and Cons <a id=\"pros_cons\"></a>\n",
    "\n",
    "The following text was taked from [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#svm).\n",
    "\n",
    "\"The advantages of support vector machines are:\n",
    "\n",
    "* Effective in high dimensional spaces.\n",
    "\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - References and Further Reading <a class=\"anchor\" id=\"References\"></a>\n",
    "\n",
    "Chris Albun cards:\n",
    "\n",
    "* [Calibrate Predicted Probabilities In SVC](https://chrisalbon.com/machine_learning/support_vector_machines/calibrate_predicted_probabilities_in_svc/)\n",
    "* [Find Support Vectors](https://chrisalbon.com/machine_learning/support_vector_machines/find_support_vectors/)\n",
    "* [Imbalanced Classes In SVM](https://chrisalbon.com/machine_learning/support_vector_machines/imbalanced_classes_in_svm/)\n",
    "* [Plot The Support Vector Classifiers Hyperplane](https://chrisalbon.com/machine_learning/support_vector_machines/plot_support_vector_classifier_hyperplane/)\n",
    "* [Support Vector Classifier](https://chrisalbon.com/machine_learning/support_vector_machines/support_vector_classifier/)\n",
    "* [SVC Parameters When Using RBF Kernel](https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/)\n",
    "\n",
    "StatQuest with Josh Starmer:\n",
    "\n",
    "* [Máquinas de Vetores de Suporte, Claramente explicadas!!!](https://www.youtube.com/watch?v=efR1C6CvhmE&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=58)\n",
    "* [Support Vector Machines Part 2: The Polynomial Kernel (Part 2 of 3)](https://www.youtube.com/watch?v=Toet3EiSFcM&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=59)\n",
    "* [Support Vector Machines Part 3: The Radial (RBF) Kernel (Part 3 of 3)](https://www.youtube.com/watch?v=Qc5IyLW_hns&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=60)\n",
    "* [Support Vector Machines in Python from Start to Finish.](https://www.youtube.com/watch?v=8A7L0GsBiLQ&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=61)\n",
    "\n",
    "Books:\n",
    "\n",
    "* [Machine Learning: An Algorithmic Perspective,Stephen Marsland, 2º edition](https://www.amazon.com/Machine-Learning-Algorithmic-Perspective-Recognition/dp/1466583282/ref=pd_sbs_1?pd_rd_w=sEWFU&pf_rd_p=527ea27c-adf6-4b67-9c5f-265eb29e0622&pf_rd_r=T8AED49NWHA6YQ5VQN3W&pd_rd_r=2b460976-2529-4ab9-ad1c-c65da5a5f14d&pd_rd_wg=xGwCt&pd_rd_i=1466583282&psc=1), pg 169-188;\n",
    "* [An Introduction to Statiscal Learning with Application in R](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf), pgs. 337-349\n",
    "\n",
    "Scikit Learn documentation:\n",
    "\n",
    "* [1.4. Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "* [sklearn.svm.SVC](https://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "* [SVM-Kernels](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_kernels.html#sphx-glr-auto-examples-svm-plot-svm-kernels-py)\n",
    "* [SVM with custom kernel](https://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py)\n",
    "* [Support vector machines (SVMs)](https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html#support-vector-machines-svms)\n",
    "* [SVM Exercise](https://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py)\n",
    "* [SVM: Separating hyperplane for unbalanced classes](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py)\n",
    "\n",
    "Medium Articles:\n",
    "\n",
    "* [Support Vector Machine (SVM) Tutorial](https://blog.statsbot.co/support-vector-machines-tutorial-c1618e635e93)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
